# üöÄ IoT City Backend - Big Data, DevSecOps & Cloud

Este projeto √© um estudo pr√°tico em **Big Data**, **DevSecOps** e **Cloud Computing** atrav√©s de uma aplica√ß√£o IoT para cidades inteligentes.

## üéØ **Tecnologias Demonstradas**

### **üìä Big Data**
- ‚úÖ **Apache Spark 3.5** - Processamento distribu√≠do de dados
- ‚úÖ **Apache Kafka** - Stream processing e mensageria
- ‚úÖ **Spark SQL** - An√°lise de dados com SQL
- ‚úÖ **RDDs e DataFrames** - Manipula√ß√£o de dados distribu√≠dos
- ‚úÖ **Spark Streaming** - Processamento de dados em tempo real

### **üîí DevSecOps**
- ‚úÖ **Spring Security** - Autentica√ß√£o e autoriza√ß√£o
- ‚úÖ **Security Headers** - HSTS, X-Frame-Options, CSP
- ‚úÖ **CORS Configuration** - Cross-origin resource sharing
- ‚úÖ **Docker Security** - Containers seguros e multi-stage builds
- ‚úÖ **Input Validation** - Valida√ß√£o de entrada e sanitiza√ß√£o

### **‚òÅÔ∏è Cloud Computing**
- ‚úÖ **Multi-cloud Support** - AWS, Azure, GCP
- ‚úÖ **Auto-scaling** - Escalabilidade autom√°tica
- ‚úÖ **Load Balancing** - Distribui√ß√£o de carga
- ‚úÖ **Environment Profiles** - Configura√ß√µes por ambiente
- ‚úÖ **Cloud-native Architecture** - Arquitetura nativa para nuvem

## üèóÔ∏è **Arquitetura**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ   API Gateway   ‚îÇ    ‚îÇ   Load Balancer ‚îÇ
‚îÇ   (React/Vue)   ‚îÇ    ‚îÇ   (Kong/Nginx)  ‚îÇ    ‚îÇ   (HAProxy)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Spring Boot    ‚îÇ
                    ‚îÇ   Application   ‚îÇ
                    ‚îÇ  (IoT Backend)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                       ‚îÇ                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   PostgreSQL    ‚îÇ    ‚îÇ   Apache Spark  ‚îÇ    ‚îÇ   Apache Kafka  ‚îÇ
‚îÇ   Database      ‚îÇ    ‚îÇ   (Big Data)    ‚îÇ    ‚îÇ   (Streaming)   ‚îÇ
‚îÇ   (Primary DB)  ‚îÇ    ‚îÇ   (Analytics)   ‚îÇ    ‚îÇ   (Real-time)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ **Como Executar**

### **1. Stack Completo (Big Data + DevSecOps)**
```bash
# Executar com Kafka, Spark e todas as funcionalidades
docker-compose -f docker-compose-bigdata.yml up --build

# Verificar status dos servi√ßos
docker-compose -f docker-compose-bigdata.yml ps

# Logs espec√≠ficos
docker-compose -f docker-compose-bigdata.yml logs -f spark
docker-compose -f docker-compose-bigdata.yml logs -f kafka
```

### **2. Stack B√°sico (Apenas IoT)**
```bash
# Executar apenas aplica√ß√£o + banco
docker-compose up --build

# Executar em background
docker-compose up -d
```

### **3. Desenvolvimento Local**
```bash
# Build e execu√ß√£o local
mvn clean install
mvn spring-boot:run -Dspring.profiles.active=bigdata

# Com debug
mvn spring-boot:run -Dspring.profiles.active=bigdata -Dspring-boot.run.jvmArguments="-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=5005"
```

## üìä **APIs Big Data**

### **An√°lise Estat√≠stica Avan√ßada**
```bash
GET /api/bigdata/analyze
```
**Resposta:**
```json
{
  "summary": {
    "averageValue": 25.5,
    "maxValue": 45.2,
    "minValue": 15.8,
    "totalRecords": 1000,
    "standardDeviation": 8.3,
    "median": 24.1
  },
  "sensorTypeDistribution": {
    "TEMPERATURE": 400,
    "HUMIDITY": 300,
    "AIR_QUALITY": 300
  },
  "geographicDistribution": {
    "Natal": 600,
    "Parnamirim": 250,
    "S√£o Gon√ßalo": 150
  },
  "performance": {
    "processingTimeMs": 150,
    "throughput": 6666.67,
    "memoryUsage": "512MB"
  }
}
```

### **An√°lise Temporal com Spark SQL**
```bash
GET /api/bigdata/temporal-patterns
```
**Resposta:**
```json
{
  "hourlyPatterns": {
    "peakHours": ["08:00", "12:00", "18:00"],
    "lowActivityHours": ["02:00", "03:00", "04:00"],
    "averageReadingsPerHour": 41.67
  },
  "dailyPatterns": {
    "weekdayAverage": 28.5,
    "weekendAverage": 26.2,
    "busiestDay": "Wednesday"
  },
  "seasonalTrends": {
    "summer": 32.1,
    "winter": 18.9,
    "spring": 25.3,
    "autumn": 27.8
  }
}
```

### **An√°lise Geogr√°fica Distribu√≠da**
```bash
GET /api/bigdata/geographic
```
**Resposta:**
```json
{
  "cityCoverage": {
    "Natal": {
      "totalDevices": 150,
      "activeDevices": 142,
      "coveragePercentage": 94.7,
      "averageSignalStrength": 85.2
    },
    "Parnamirim": {
      "totalDevices": 75,
      "activeDevices": 68,
      "coveragePercentage": 90.7,
      "averageSignalStrength": 78.9
    }
  },
  "hotspots": [
    {
      "location": "Centro de Natal",
      "deviceDensity": "high",
      "averageReadings": 45.2
    }
  ],
  "coverageGaps": [
    {
      "area": "Zona Norte",
      "reason": "Low population density",
      "recommendation": "Add 3 more devices"
    }
  ]
}
```

### **M√©tricas de Performance em Tempo Real**
```bash
GET /api/bigdata/performance
```
**Resposta:**
```json
{
  "systemMetrics": {
    "totalRecords": 1000,
    "averageValue": 25.5,
    "processingTimeMs": 150,
    "throughput": 6666.67,
    "memoryUsage": "512MB",
    "cpuUsage": "23%"
  },
  "sparkMetrics": {
    "activeJobs": 2,
    "completedJobs": 45,
    "failedJobs": 0,
    "executorMemory": "2GB",
    "driverMemory": "1GB"
  },
  "kafkaMetrics": {
    "messagesPerSecond": 1250,
    "lag": 0,
    "consumerGroups": 3,
    "partitions": 8
  }
}
```

### **Streaming Analytics**
```bash
POST /api/bigdata/stream/start
```
**Inicia processamento de streaming:**
```json
{
  "streamConfig": {
    "windowSize": "5 minutes",
    "slideInterval": "1 minute",
    "topics": ["sensor-data", "device-status"],
    "outputFormat": "json"
  }
}
```

## üîí **Seguran√ßa (DevSecOps)**

### **Security Headers Implementados**
```java
// Configura√ß√£o completa de seguran√ßa
http
    .headers()
        .frameOptions().deny()                    // Preven√ß√£o de clickjacking
        .contentTypeOptions().and()               // Preven√ß√£o de MIME sniffing
        .httpStrictTransportSecurity(hstsConfig -> hstsConfig
            .maxAgeInSeconds(31536000)            // 1 ano
            .includeSubdomains(true)
            .preload(true)
        ).and()
        .contentSecurityPolicy(csp -> csp
            .policyDirectives("default-src 'self'; script-src 'self' 'unsafe-inline'")
        ).and()
        .referrerPolicy(ReferrerPolicyHeaderWriter.ReferrerPolicy.STRICT_ORIGIN_WHEN_CROSS_ORIGIN)
    .and()
    .cors(cors -> cors.configurationSource(corsConfigurationSource()))
    .csrf(csrf -> csrf.disable())                 // Para APIs REST
    .authorizeHttpRequests(auth -> auth
        .requestMatchers("/api/public/**").permitAll()
        .requestMatchers("/actuator/health").permitAll()
        .anyRequest().authenticated()
    );
```

### **CORS Configuration**
```java
@Bean
public CorsConfigurationSource corsConfigurationSource() {
    CorsConfiguration configuration = new CorsConfiguration();
    configuration.setAllowedOriginPatterns(Arrays.asList("http://localhost:3000", "https://*.iotcity.com"));
    configuration.setAllowedMethods(Arrays.asList("GET", "POST", "PUT", "DELETE", "OPTIONS"));
    configuration.setAllowedHeaders(Arrays.asList("*"));
    configuration.setAllowCredentials(true);
    configuration.setMaxAge(3600L);
    
    UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
    source.registerCorsConfiguration("/**", configuration);
    return source;
}
```

### **Docker Security Best Practices**
```dockerfile
# Multi-stage build para seguran√ßa
FROM openjdk:17-jdk-slim AS builder
WORKDIR /app
COPY pom.xml .
COPY src ./src
RUN mvn clean package -DskipTests

FROM openjdk:17-jre-slim AS runtime
# Usu√°rio n√£o-root
RUN groupadd -r iotcity && useradd -r -g iotcity iotcity
USER iotcity

# Diret√≥rio de trabalho
WORKDIR /app

# Copiar apenas o JAR necess√°rio
COPY --from=builder /app/target/*.jar app.jar

# Configura√ß√µes de seguran√ßa
ENV JAVA_OPTS="-Djava.security.egd=file:/dev/./urandom -XX:+UseContainerSupport"

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8080/actuator/health || exit 1

EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]
```

### **Input Validation e Sanitiza√ß√£o**
```java
@RestController
@Validated
public class SensorDataController {
    
    @PostMapping("/api/sensor-data")
    public ResponseEntity<SensorData> createSensorData(
            @Valid @RequestBody SensorDataDTO sensorData) {
        // Valida√ß√£o autom√°tica via Bean Validation
        return ResponseEntity.ok(sensorDataService.save(sensorData));
    }
}

public class SensorDataDTO {
    @NotNull
    @Min(0)
    @Max(100)
    private Double value;
    
    @NotNull
    @Pattern(regexp = "^[A-Z_]+$")
    private String sensorType;
    
    @NotNull
    @Size(min = 1, max = 100)
    private String location;
    
    // Getters e setters
}
```

## ‚òÅÔ∏è **Cloud Computing**

### **Configura√ß√µes Multi-Cloud**
```yaml
# application-cloud.yml
cloud:
  provider: aws  # aws, azure, gcp
  region: us-east-1
  instance-type: t3.medium
  auto-scaling:
    enabled: true
    min-instances: 2
    max-instances: 10
    target-cpu-utilization: 70
  load-balancer:
    enabled: true
    health-check-path: /actuator/health
    sticky-sessions: true
  database:
    rds:
      instance-class: db.t3.micro
      multi-az: true
      backup-retention: 7
  monitoring:
    cloudwatch:
      enabled: true
      metrics-interval: 60
```

### **Perfis de Ambiente**
```properties
# application-bigdata.properties
spring.profiles.active=bigdata
spark.master=spark://spark-master:7077
kafka.bootstrap-servers=kafka:9092
spring.jpa.hibernate.ddl-auto=update
logging.level.org.apache.spark=INFO
logging.level.org.apache.kafka=INFO

# application-cloud.properties
spring.profiles.active=cloud
spring.datasource.url=${RDS_URL}
spring.datasource.username=${RDS_USERNAME}
spring.datasource.password=${RDS_PASSWORD}
management.endpoints.web.exposure.include=health,info,metrics
```

### **Auto-scaling Configuration**
```java
@Configuration
@Profile("cloud")
public class CloudConfig {
    
    @Bean
    @ConditionalOnProperty(name = "cloud.auto-scaling.enabled", havingValue = "true")
    public AutoScalingService autoScalingService() {
        return new AutoScalingService();
    }
    
    @Bean
    public LoadBalancer loadBalancer() {
        return new LoadBalancer();
    }
}
```

## üìà **Monitoramento e Observabilidade**

### **Health Checks**
```bash
# Aplica√ß√£o principal
curl http://localhost:8080/actuator/health

# Spark cluster
curl http://localhost:8081/api/v1/applications

# Kafka cluster
curl http://localhost:9092/topics

# PostgreSQL
pg_isready -h localhost -p 5432
```

### **M√©tricas Dispon√≠veis**
- **Application Metrics**: Request count, response time, error rate
- **Big Data Metrics**: Spark job duration, memory usage, throughput
- **Infrastructure Metrics**: CPU, memory, disk usage
- **Business Metrics**: Active devices, data volume, coverage percentage

### **Logging Configuration**
```yaml
logging:
  level:
    com.iotcitybackend: INFO
    org.apache.spark: WARN
    org.apache.kafka: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/iot-city-backend.log
    max-size: 100MB
    max-history: 30
```

## üõ†Ô∏è **Stack Tecnol√≥gica Detalhada**

### **Backend Core**
- **Spring Boot 3.5** - Framework principal com suporte a GraalVM
- **Spring Security 6** - Seguran√ßa moderna com OAuth2/JWT
- **Spring Data JPA** - Persist√™ncia com Hibernate
- **Spring Boot Actuator** - Monitoramento e m√©tricas
- **Spring Cloud** - Microservices e configura√ß√£o distribu√≠da

### **Big Data Stack**
- **Apache Spark 3.5** - Processamento distribu√≠do com Scala/Java
- **Apache Kafka 3.5** - Stream processing e mensageria
- **Spark SQL** - An√°lise de dados com SQL
- **Spark Streaming** - Processamento em tempo real
- **Delta Lake** - Lakehouse para dados estruturados

### **DevOps & Security**
- **Docker 24** - Containeriza√ß√£o com multi-stage builds
- **Docker Compose** - Orquestra√ß√£o local
- **Kubernetes** - Orquestra√ß√£o em produ√ß√£o
- **Helm Charts** - Gerenciamento de deployments
- **SonarQube** - An√°lise de qualidade de c√≥digo

### **Cloud & Infrastructure**
- **AWS ECS/EKS** - Container orchestration
- **Azure AKS** - Kubernetes managed
- **Google GKE** - Kubernetes no Google Cloud
- **Terraform** - Infrastructure as Code
- **Prometheus + Grafana** - Monitoring stack

## üéØ **Demonstra Conhecimento em**

### **Big Data Engineering**
‚úÖ **Spark RDDs** - Resilient Distributed Datasets  
‚úÖ **Spark DataFrames** - Manipula√ß√£o estruturada de dados  
‚úÖ **Spark SQL** - An√°lise com linguagem SQL  
‚úÖ **Spark Streaming** - Processamento em tempo real  
‚úÖ **Kafka Integration** - Stream processing  
‚úÖ **Performance Optimization** - Tuning de jobs Spark  
‚úÖ **Data Pipeline Design** - ETL/ELT pipelines  

### **DevSecOps Practices**
‚úÖ **Security Headers** - HSTS, CSP, X-Frame-Options  
‚úÖ **CORS Configuration** - Cross-origin security  
‚úÖ **Input Validation** - Bean Validation e sanitiza√ß√£o  
‚úÖ **Docker Security** - Multi-stage builds, non-root users  
‚úÖ **Environment Management** - Perfis e configura√ß√µes  
‚úÖ **CI/CD Pipeline** - Automated testing e deployment  
‚úÖ **Security Scanning** - Vulnerability assessment  

### **Cloud Computing**
‚úÖ **Multi-cloud Support** - AWS, Azure, GCP  
‚úÖ **Auto-scaling** - Escalabilidade autom√°tica  
‚úÖ **Load Balancing** - Distribui√ß√£o de carga  
‚úÖ **Configuration Management** - Externalized configuration  
‚úÖ **Cloud-native Design** - 12-factor app principles  
‚úÖ **Infrastructure as Code** - Terraform/CloudFormation  
‚úÖ **Monitoring & Alerting** - Observability stack  

## üìä **Acessos e URLs**

### **APIs e Documenta√ß√£o**
- **Base URL:** `http://localhost:8080/api/`
- **Swagger UI:** `http://localhost:8080/swagger-ui.html`
- **OpenAPI JSON:** `http://localhost:8080/api-docs`
- **Health Check:** `http://localhost:8080/actuator/health`
- **Metrics:** `http://localhost:8080/actuator/metrics`

### **Big Data Tools**
- **Spark UI:** `http://localhost:8081` (Master)
- **Spark History Server:** `http://localhost:18080`
- **Kafka UI:** `http://localhost:9000`
- **Kafka Broker:** `localhost:9092`
- **Zookeeper:** `localhost:2181`

### **Infrastructure**
- **PostgreSQL:** `localhost:5432`
- **Redis (Cache):** `localhost:6379`
- **Elasticsearch:** `localhost:9200`
- **Kibana:** `http://localhost:5601`

## üöÄ **Pr√≥ximos Passos**

### **Melhorias Planejadas**
- [ ] **Machine Learning** - Integra√ß√£o com MLlib para predi√ß√µes
- [ ] **Real-time Analytics** - Dashboards em tempo real
- [ ] **Edge Computing** - Processamento na borda
- [ ] **Blockchain** - Integridade de dados com blockchain
- [ ] **5G Integration** - Suporte a redes 5G
- [ ] **AI/ML Pipeline** - Pipeline completo de ML

### **Escalabilidade**
- [ ] **Microservices** - Decomposi√ß√£o em microservi√ßos
- [ ] **Event Sourcing** - Arquitetura baseada em eventos
- [ ] **CQRS** - Command Query Responsibility Segregation
- [ ] **Distributed Tracing** - Jaeger/Zipkin integration

